[project]
name = "openai-llm-proxy"
version = "0.1.0"
description = "基于LiteLLM的多厂商LLM代理服务，提供OpenAI兼容的API接口"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "fastapi>=0.115.12",
    "httpx>=0.28.1",
    "litellm>=1.72.2",
    "pydantic>=2.11.5",
    "pydantic-settings>=2.9.1",
    "python-dotenv>=1.1.0",
    "pyyaml>=6.0.2",
    "socksio>=1.0.0",
    "uvicorn>=0.34.3",
]

[dependency-groups]
dev = [
    "types-pyyaml>=6.0.12.20250516",
]
