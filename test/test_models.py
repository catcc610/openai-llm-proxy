#!/usr/bin/env python3
"""
LLMä»£ç†æœåŠ¡æ¨¡å‹æµ‹è¯•è„šæœ¬
æµ‹è¯•é…ç½®æ–‡ä»¶ä¸­æ‰€æœ‰æ¨¡å‹çš„å„ç§åŠŸèƒ½ï¼šæµå¼ã€éæµå¼ã€å·¥å…·è°ƒç”¨ã€å¤šæ¨¡æ€
"""

import asyncio
import json
import time
import yaml
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from openai import OpenAI
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""

    model: str
    test_type: str
    success: bool
    response_time: float
    error: Optional[str] = None
    response_preview: Optional[str] = None


class ModelTester:
    """æ¨¡å‹æµ‹è¯•å™¨"""

    def __init__(
        self, base_url: str = "http://localhost:9000/v1", api_key: str = "dummy"
    ):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.client = OpenAI(base_url=base_url, api_key=api_key)
        self.results: List[TestResult] = []

        # ä¸æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹åˆ—è¡¨
        self.no_multimodal_models = {"deepseek-v3-0324"}

        # æµ‹è¯•ç”¨çš„å›¾ç‰‡
        # 1. çœŸå®å›¾ç‰‡URL
        self.test_image_url = (
            "https://mag.npf.co.jp/wp-content/uploads/2023/10/27750021_m.jpg"
        )

        # 2. é»„è‰²å›¾ç‰‡çš„base64 (100x100åƒç´ çš„é»„è‰²PNG)
        self.yellow_image_base64 = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=="

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = Path("../external_llm/external_llm.yaml")
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)

        logger.info(
            f"âœ… åŠ è½½é…ç½®æ–‡ä»¶æˆåŠŸï¼Œæ‰¾åˆ° {len(config.get('model_config', {}))} ä¸ªæ¨¡å‹"
        )
        return config

    def get_test_models(self) -> List[str]:
        """è·å–éœ€è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨"""
        config = self.load_config()
        models = list(config.get("model_config", {}).keys())
        logger.info(f"ğŸ“‹ å¾…æµ‹è¯•æ¨¡å‹: {', '.join(models)}")
        return models

    async def test_basic_chat(self, model: str) -> TestResult:
        """æµ‹è¯•åŸºç¡€èŠå¤©åŠŸèƒ½ï¼ˆéæµå¼ï¼‰"""
        start_time = time.time()

        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Œä¸è¶…è¿‡50å­—"}
                ],
                max_tokens=100,
                temperature=0.7,
            )

            response_time = time.time() - start_time
            content = response.choices[0].message.content

            return TestResult(
                model=model,
                test_type="åŸºç¡€èŠå¤©",
                success=True,
                response_time=response_time,
                response_preview=content[:100] if content else "æ— å†…å®¹",
            )

        except Exception as e:
            return TestResult(
                model=model,
                test_type="åŸºç¡€èŠå¤©",
                success=False,
                response_time=time.time() - start_time,
                error=str(e),
            )

    async def test_streaming_chat(self, model: str) -> TestResult:
        """æµ‹è¯•æµå¼èŠå¤©åŠŸèƒ½"""
        start_time = time.time()

        try:
            stream = self.client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯æè¿°äººå·¥æ™ºèƒ½çš„æœªæ¥"}],
                max_tokens=100,
                temperature=0.7,
                stream=True,
            )

            content_parts = []
            first_chunk_time = None

            for chunk in stream:
                if first_chunk_time is None:
                    first_chunk_time = time.time() - start_time

                if chunk.choices[0].delta.content:
                    content_parts.append(chunk.choices[0].delta.content)

            total_time = time.time() - start_time
            full_content = "".join(content_parts)

            return TestResult(
                model=model,
                test_type="æµå¼èŠå¤©",
                success=True,
                response_time=total_time,
                response_preview=f"é¦–Token: {first_chunk_time:.2f}s | å†…å®¹: {full_content[:50]}...",
            )

        except Exception as e:
            return TestResult(
                model=model,
                test_type="æµå¼èŠå¤©",
                success=False,
                response_time=time.time() - start_time,
                error=str(e),
            )

    async def test_tool_calling(self, model: str) -> TestResult:
        """æµ‹è¯•å·¥å…·è°ƒç”¨åŠŸèƒ½"""
        start_time = time.time()

        # å®šä¹‰æµ‹è¯•å·¥å…·
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {"type": "string", "description": "åŸå¸‚åç§°"},
                            "unit": {
                                "type": "string",
                                "enum": ["celsius", "fahrenheit"],
                                "description": "æ¸©åº¦å•ä½",
                            },
                        },
                        "required": ["city"],
                    },
                },
            }
        ]

        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": "è¯·å¸®æˆ‘æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”"}],
                tools=tools,
                tool_choice="auto",
                max_tokens=200,
            )

            response_time = time.time() - start_time
            message = response.choices[0].message

            if message.tool_calls:
                tool_call = message.tool_calls[0]
                function_name = tool_call.function.name
                function_args = tool_call.function.arguments

                return TestResult(
                    model=model,
                    test_type="å·¥å…·è°ƒç”¨",
                    success=True,
                    response_time=response_time,
                    response_preview=f"è°ƒç”¨å‡½æ•°: {function_name}({function_args})",
                )
            else:
                return TestResult(
                    model=model,
                    test_type="å·¥å…·è°ƒç”¨",
                    success=False,
                    response_time=response_time,
                    error="æ¨¡å‹æœªè°ƒç”¨å·¥å…·",
                )

        except Exception as e:
            return TestResult(
                model=model,
                test_type="å·¥å…·è°ƒç”¨",
                success=False,
                response_time=time.time() - start_time,
                error=str(e),
            )

    async def test_multimodal(self, model: str) -> TestResult:
        """æµ‹è¯•å¤šæ¨¡æ€åŠŸèƒ½"""
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
        if model in self.no_multimodal_models:
            return TestResult(
                model=model,
                test_type="å¤šæ¨¡æ€",
                success=False,
                response_time=0.0,
                error="æ¨¡å‹ä¸æ”¯æŒå¤šæ¨¡æ€åŠŸèƒ½",
            )

        start_time = time.time()

        try:
            # æµ‹è¯•1: ä½¿ç”¨çœŸå®å›¾ç‰‡URL
            response1 = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å…ƒç´ å’Œåœºæ™¯ã€‚",
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": self.test_image_url,
                                    "detail": "high",
                                },
                            },
                        ],
                    }
                ],
                max_tokens=200,
            )

            # æµ‹è¯•2: ä½¿ç”¨base64é»„è‰²å›¾ç‰‡
            response2 = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "è¿™å¼ å›¾ç‰‡æ˜¯ä»€ä¹ˆé¢œè‰²ï¼Ÿè¯·ç®€å•æè¿°ã€‚",
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{self.yellow_image_base64}",
                                    "detail": "low",
                                },
                            },
                        ],
                    }
                ],
                max_tokens=100,
            )

            response_time = time.time() - start_time

            # åˆå¹¶ä¸¤ä¸ªæµ‹è¯•çš„ç»“æœ
            content1 = response1.choices[0].message.content or ""
            content2 = response2.choices[0].message.content or ""

            combined_preview = (
                f"URLå›¾ç‰‡: {content1[:80]}... | Base64å›¾ç‰‡: {content2[:80]}..."
            )

            return TestResult(
                model=model,
                test_type="å¤šæ¨¡æ€",
                success=True,
                response_time=response_time,
                response_preview=combined_preview,
            )

        except Exception as e:
            return TestResult(
                model=model,
                test_type="å¤šæ¨¡æ€",
                success=False,
                response_time=time.time() - start_time,
                error=str(e),
            )

    async def test_model_comprehensive(self, model: str) -> List[TestResult]:
        """å¯¹å•ä¸ªæ¨¡å‹è¿›è¡Œå…¨é¢æµ‹è¯•"""
        logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹: {model}")

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        tasks = [
            self.test_basic_chat(model),
            self.test_streaming_chat(model),
            self.test_tool_calling(model),
            self.test_multimodal(model),
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                test_types = ["åŸºç¡€èŠå¤©", "æµå¼èŠå¤©", "å·¥å…·è°ƒç”¨", "å¤šæ¨¡æ€"]
                processed_results.append(
                    TestResult(
                        model=model,
                        test_type=test_types[i],
                        success=False,
                        response_time=0.0,
                        error=f"æµ‹è¯•å¼‚å¸¸: {str(result)}",
                    )
                )
            else:
                processed_results.append(result)

        return processed_results

    def print_results(self, results: List[TestResult]) -> None:
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\n" + "=" * 80)
        print("ğŸ§ª LLMä»£ç†æœåŠ¡æ¨¡å‹æµ‹è¯•æŠ¥å‘Š")
        print("=" * 80)

        # æŒ‰æ¨¡å‹åˆ†ç»„
        models = {}
        for result in results:
            if result.model not in models:
                models[result.model] = []
            models[result.model].append(result)

        # ç»Ÿè®¡ä¿¡æ¯
        total_tests = len(results)
        successful_tests = sum(1 for r in results if r.success)

        print("\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"   æˆåŠŸæ•°: {successful_tests}")
        print(f"   å¤±è´¥æ•°: {total_tests - successful_tests}")
        print(f"   æˆåŠŸç‡: {successful_tests / total_tests * 100:.1f}%")

        # è¯¦ç»†ç»“æœ
        for model, model_results in models.items():
            print(f"\nğŸ¤– æ¨¡å‹: {model}")
            print("-" * 60)

            for result in model_results:
                status = "âœ…" if result.success else "âŒ"
                print(
                    f"   {status} {result.test_type:<12} | "
                    f"è€—æ—¶: {result.response_time:.2f}s"
                )

                if result.success and result.response_preview:
                    print(f"      ğŸ“ å“åº”: {result.response_preview}")
                elif not result.success and result.error:
                    print(f"      âš ï¸  é”™è¯¯: {result.error}")

        print("\n" + "=" * 80)

    def save_results_json(
        self, results: List[TestResult], filename: str = "test_results.json"
    ) -> None:
        """ä¿å­˜æµ‹è¯•ç»“æœä¸ºJSONæ–‡ä»¶"""
        results_data = []
        for result in results:
            results_data.append(
                {
                    "model": result.model,
                    "test_type": result.test_type,
                    "success": result.success,
                    "response_time": result.response_time,
                    "error": result.error,
                    "response_preview": result.response_preview,
                    "timestamp": time.time(),
                }
            )

        with open(filename, "w", encoding="utf-8") as f:
            json.dump(results_data, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")

    async def run_all_tests(self) -> None:
        """è¿è¡Œæ‰€æœ‰æ¨¡å‹çš„å…¨é¢æµ‹è¯•"""
        try:
            models = self.get_test_models()
            if not models:
                logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æµ‹è¯•çš„æ¨¡å‹")
                return

            logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯• {len(models)} ä¸ªæ¨¡å‹...")

            all_results = []
            for model in models:
                try:
                    model_results = await self.test_model_comprehensive(model)
                    all_results.extend(model_results)

                    # æ¨¡å‹é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    await asyncio.sleep(1)

                except Exception as e:
                    logger.error(f"âŒ æµ‹è¯•æ¨¡å‹ {model} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

            # è¾“å‡ºç»“æœ
            self.print_results(all_results)
            self.save_results_json(all_results)

            logger.info("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª LLMä»£ç†æœåŠ¡æ¨¡å‹æµ‹è¯•å·¥å…·")
    print("=" * 50)

    # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
    tester = ModelTester()
    try:
        # ç®€å•çš„å¥åº·æ£€æŸ¥
        import httpx

        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:9000/health", timeout=5.0)
            if response.status_code != 200:
                logger.error("âŒ LLMä»£ç†æœåŠ¡æœªæ­£å¸¸è¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡")
                return
    except Exception as e:
        logger.error(f"âŒ æ— æ³•è¿æ¥åˆ°LLMä»£ç†æœåŠ¡: {e}")
        logger.info("ğŸ’¡ è¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨: python main.py")
        return

    logger.info("âœ… LLMä»£ç†æœåŠ¡è¿æ¥æ­£å¸¸")

    # è¿è¡Œæµ‹è¯•
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())
