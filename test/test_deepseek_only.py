"""
ç®€åŒ–çš„DeepSeekæ¨¡å‹æµ‹è¯•è„šæœ¬
åªæµ‹è¯•ç«å±±å¼•æ“çš„DeepSeekæ¨¡å‹
"""

import asyncio
import time
from typing import Optional

try:
    import openai
    from openai import OpenAI, AsyncOpenAI
except ImportError:
    print("âŒ æœªå®‰è£…openaiåŒ…ï¼Œè¯·è¿è¡Œ: uv add openai")
    exit(1)


# é…ç½®
BASE_URL = "http://localhost:9000/v1"
API_KEY = "dummy"
MODEL_NAME = "deepseek-v3-0324"
TIMEOUT = 30


class DeepSeekTester:
    """DeepSeekæ¨¡å‹æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.client = OpenAI(base_url=BASE_URL, api_key=API_KEY, timeout=TIMEOUT)
        self.async_client = AsyncOpenAI(base_url=BASE_URL, api_key=API_KEY, timeout=TIMEOUT)
    
    def test_basic_chat(self) -> bool:
        """æµ‹è¯•åŸºæœ¬èŠå¤©åŠŸèƒ½"""
        print("ğŸ§ª æµ‹è¯•åŸºæœ¬èŠå¤©...")
        start_time = time.time()
        
        try:
            response = self.client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”ã€‚"},
                    {"role": "user", "content": "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Œä¸è¶…è¿‡100å­—ã€‚"}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            response_time = time.time() - start_time
            content = response.choices[0].message.content or ""
            
            print(f"âœ… åŸºæœ¬èŠå¤©æµ‹è¯•æˆåŠŸ ({response_time:.2f}s)")
            print(f"ğŸ“ å›å¤å†…å®¹: {content[:100]}...")
            return True
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬èŠå¤©æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_streaming_chat(self) -> bool:
        """æµ‹è¯•æµå¼èŠå¤©"""
        print("\nğŸ§ª æµ‹è¯•æµå¼èŠå¤©...")
        start_time = time.time()
        
        try:
            stream = self.client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": "å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"}],
                max_tokens=300,
                stream=True
            )
            
            content_parts = []
            first_token_time = None
            
            for chunk in stream:
                if first_token_time is None:
                    first_token_time = time.time()
                    
                if chunk.choices[0].delta.content:
                    content_parts.append(chunk.choices[0].delta.content)
            
            total_time = time.time() - start_time
            full_content = "".join(content_parts)
            
            print(f"âœ… æµå¼èŠå¤©æµ‹è¯•æˆåŠŸ ({total_time:.2f}s)")
            print(f"ğŸ“ ç”Ÿæˆå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")
            return True
            
        except Exception as e:
            print(f"âŒ æµå¼èŠå¤©æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_async_chat(self) -> bool:
        """æµ‹è¯•å¼‚æ­¥èŠå¤©"""
        print("\nğŸ§ª æµ‹è¯•å¼‚æ­¥èŠå¤©...")
        start_time = time.time()
        
        try:
            response = await self.async_client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": "ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"}],
                max_tokens=100
            )
            
            response_time = time.time() - start_time
            content = response.choices[0].message.content or ""
            
            print(f"âœ… å¼‚æ­¥èŠå¤©æµ‹è¯•æˆåŠŸ ({response_time:.2f}s)")
            print(f"ğŸ“ å›å¤å†…å®¹: {content}")
            return True
            
        except Exception as e:
            print(f"âŒ å¼‚æ­¥èŠå¤©æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_concurrent_requests(self, num_requests: int = 3) -> bool:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
        print(f"\nğŸ§ª æµ‹è¯•å¹¶å‘è¯·æ±‚ ({num_requests}ä¸ª)...")
        start_time = time.time()
        
        try:
            tasks = []
            for i in range(num_requests):
                task = self.async_client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[{"role": "user", "content": f"è¿™æ˜¯ç¬¬{i+1}ä¸ªå¹¶å‘è¯·æ±‚ï¼Œè¯·ç®€å•å›å¤"}],
                    max_tokens=50
                )
                tasks.append(task)
            
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            successful_responses = [r for r in responses if not isinstance(r, Exception)]
            
            total_time = time.time() - start_time
            success_rate = len(successful_responses) / num_requests * 100
            
            print(f"âœ… å¹¶å‘è¯·æ±‚æµ‹è¯•å®Œæˆ ({total_time:.2f}s)")
            print(f"ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}% ({len(successful_responses)}/{num_requests})")
            
            return len(successful_responses) == num_requests
            
        except Exception as e:
            print(f"âŒ å¹¶å‘è¯·æ±‚æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_model_list(self) -> bool:
        """æµ‹è¯•æ¨¡å‹åˆ—è¡¨"""
        print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åˆ—è¡¨...")
        
        try:
            models = self.client.models.list()
            model_names = [model.id for model in models.data]
            
            print(f"âœ… æ¨¡å‹åˆ—è¡¨è·å–æˆåŠŸ")
            print(f"ğŸ“ å¯ç”¨æ¨¡å‹: {model_names}")
            
            if MODEL_NAME in model_names:
                print(f"âœ… ç›®æ ‡æ¨¡å‹ {MODEL_NAME} åœ¨åˆ—è¡¨ä¸­")
                return True
            else:
                print(f"âŒ ç›®æ ‡æ¨¡å‹ {MODEL_NAME} ä¸åœ¨åˆ—è¡¨ä¸­")
                return False
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆ—è¡¨æµ‹è¯•å¤±è´¥: {e}")
            return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ DeepSeekæ¨¡å‹æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    print(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {MODEL_NAME}")
    print(f"ğŸ”— æœåŠ¡åœ°å€: {BASE_URL}")
    print("=" * 50)
    
    tester = DeepSeekTester()
    results = []
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results.append(("æ¨¡å‹åˆ—è¡¨", tester.test_model_list()))
        results.append(("åŸºæœ¬èŠå¤©", tester.test_basic_chat()))
        results.append(("æµå¼èŠå¤©", tester.test_streaming_chat()))
        results.append(("å¼‚æ­¥èŠå¤©", await tester.test_async_chat()))
        results.append(("å¹¶å‘è¯·æ±‚", await tester.test_concurrent_requests(3)))
        
        # ç»Ÿè®¡ç»“æœ
        total_tests = len(results)
        passed_tests = sum(1 for _, success in results if success)
        
        print("\n" + "=" * 50)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 50)
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æ•°: {passed_tests} âœ…")
        print(f"å¤±è´¥æ•°: {total_tests - passed_tests} âŒ")
        print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
        
        # æ˜¾ç¤ºå¤±è´¥çš„æµ‹è¯•
        failed_tests = [name for name, success in results if not success]
        if failed_tests:
            print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•: {', '.join(failed_tests)}")
        else:
            print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
        
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿è¡Œå‡ºé”™: {e}")
    finally:
        await tester.async_client.close()


if __name__ == "__main__":
    asyncio.run(main()) 