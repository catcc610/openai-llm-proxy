# OpenAI LLM Proxy

ğŸš€ åŸºäºLiteLLMçš„å¤šå‚å•†LLMä»£ç†æœåŠ¡ï¼Œæä¾›OpenAIå…¼å®¹çš„APIæ¥å£

## âœ¨ ç‰¹æ€§

- ğŸ”— **OpenAIå…¼å®¹API** - å®Œå…¨å…¼å®¹OpenAI ChatGPT APIæ ¼å¼
- ğŸŒ **å¤šå‚å•†æ”¯æŒ** - æ”¯æŒç«å±±å¼•æ“ã€ç™¾åº¦æ–‡å¿ƒã€é˜¿é‡Œé€šä¹‰ç­‰å¤šä¸ªLLMæä¾›å•†
- âš¡ **é«˜æ€§èƒ½** - åŸºäºFastAPIæ„å»ºï¼Œæ”¯æŒå¼‚æ­¥å¤„ç†å’Œæµå¼å“åº”
- ğŸ›¡ï¸ **ç±»å‹å®‰å…¨** - ä½¿ç”¨Pydanticå’Œå¼ºç±»å‹ç³»ç»Ÿï¼Œé€šè¿‡MyPyæ£€æŸ¥
- ğŸ“Š **å®Œå–„ç›‘æ§** - è¯·æ±‚IDè¿½è¸ªã€è¯¦ç»†æ—¥å¿—è®°å½•ã€é”™è¯¯å¤„ç†
- ğŸ”§ **çµæ´»é…ç½®** - YAMLé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒçƒ­é‡è½½
- ğŸ—ï¸ **ç”Ÿäº§å°±ç»ª** - å®Œå–„çš„é”™è¯¯å¤„ç†ã€ä¸­é—´ä»¶æ”¯æŒã€æ ‡å‡†åŒ–å“åº”

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.11+
- uv (æ¨èçš„åŒ…ç®¡ç†å™¨)

### å¿«é€Ÿå¼€å§‹

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd openai-llm-proxy

# å®‰è£…ä¾èµ–
make init

# å¤åˆ¶é…ç½®æ–‡ä»¶
cp config/.axample config/config.yaml

# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„APIå¯†é’¥
vim config/config.yaml

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
make run
```

## âš™ï¸ é…ç½®

### åŸºç¡€é…ç½®

ç¼–è¾‘ `config/config.yaml` æ–‡ä»¶ï¼š

```yaml
# ç¯å¢ƒå˜é‡è®¾ç½®
os_env:
  VOLCENGINE_API_KEY: "your-volcengine-api-key"
  OPENAI_API_KEY: "your-openai-api-key"
  ANTHROPIC_API_KEY: "your-anthropic-api-key"

# æ¨¡å‹é…ç½®æ˜ å°„ - æŒ‡å®šæ¯ä¸ªæ¨¡å‹ä½¿ç”¨çš„æä¾›å•†
model_config:
  "gpt-3.5-turbo": openai
  "gpt-4": openai
  "claude-3-sonnet": anthropic
  "deepseek-v3": volcengine

# æ¨¡å‹è·¯ç”±é…ç½® - æ¯ä¸ªæä¾›å•†çš„å…·ä½“æ¨¡å‹æ˜ å°„
model_routes:
  openai:
    "gpt-3.5-turbo": "gpt-3.5-turbo"
    "gpt-4": "gpt-4"
  anthropic:
    "claude-3-sonnet": "claude-3-sonnet-20240229"
  volcengine:
    "deepseek-v3": "deepseek-v3-250324"

# æœåŠ¡å™¨é…ç½®
server:
  host: "0.0.0.0"
  port: 8000
  reload: false
  log_level: "info"

# ä»£ç†é…ç½®
proxy:
  timeout: 30
  max_retries: 3
  default_model: "gpt-3.5-turbo"

# å®‰å…¨é…ç½®
security:
  api_keys: []  # å¯é€‰ï¼šAPIå¯†é’¥åˆ—è¡¨
```

### æ”¯æŒçš„æä¾›å•†

| æä¾›å•† | æ ‡è¯†ç¬¦ | æ”¯æŒçš„æ¨¡å‹ |
|--------|--------|-----------|
| OpenAI | `openai` | GPT-3.5, GPT-4, GPT-4o |
| Anthropic | `anthropic` | Claude-3 ç³»åˆ— |
| ç«å±±å¼•æ“ | `volcengine` | DeepSeek, Doubao |
| ç™¾åº¦æ–‡å¿ƒ | `baidu` | ERNIE ç³»åˆ— |
| é˜¿é‡Œé€šä¹‰ | `alibaba` | Qwen ç³»åˆ— |

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨æœåŠ¡

```bash
# å¼€å‘æ¨¡å¼ï¼ˆçƒ­é‡è½½ï¼‰
make run

# ç”Ÿäº§æ¨¡å¼
make start

# è‡ªå®šä¹‰å‚æ•°
python main.py --host 0.0.0.0 --port 8080 --reload
```

### APIè°ƒç”¨ç¤ºä¾‹

#### éæµå¼è¯·æ±‚

```python
import requests

response = requests.post(
    "http://localhost:8000/v1/chat/completions",
    headers={"Content-Type": "application/json"},
    json={
        "model": "deepseek-v3",
        "messages": [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
        ],
        "temperature": 0.7,
        "max_tokens": 1000
    }
)

print(response.json())
```

#### æµå¼è¯·æ±‚

```python
import requests

response = requests.post(
    "http://localhost:8000/v1/chat/completions",
    headers={"Content-Type": "application/json"},
    json={
        "model": "deepseek-v3",
        "messages": [
            {"role": "user", "content": "è¯·å†™ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹"}
        ],
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

#### ä½¿ç”¨OpenAI SDK

```python
from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯æŒ‡å‘æœ¬åœ°ä»£ç†
client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"  # å¦‚æœæ²¡æœ‰é…ç½®APIå¯†é’¥éªŒè¯
)

response = client.chat.completions.create(
    model="deepseek-v3",
    messages=[
        {"role": "user", "content": "Hello, world!"}
    ]
)

print(response.choices[0].message.content)
```

## ğŸ”— APIæ–‡æ¡£

å¯åŠ¨æœåŠ¡åï¼Œè®¿é—®ä»¥ä¸‹åœ°å€æŸ¥çœ‹APIæ–‡æ¡£ï¼š

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### ä¸»è¦ç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° |
|------|------|------|
| `/` | GET | å¥åº·æ£€æŸ¥ |
| `/health` | GET | è¯¦ç»†å¥åº·æ£€æŸ¥ |
| `/config` | GET | è·å–é…ç½®ä¿¡æ¯ |
| `/config/reload` | POST | é‡æ–°åŠ è½½é…ç½® |
| `/v1/chat/completions` | POST | èŠå¤©å®Œæˆï¼ˆOpenAIå…¼å®¹ï¼‰ |

## ğŸ› ï¸ å¼€å‘

### ç¯å¢ƒè®¾ç½®

```bash
# å®‰è£…å¼€å‘ä¾èµ–
uv add --dev pytest pytest-asyncio httpx

# å®‰è£…å¼€å‘å·¥å…·ï¼ˆå¦‚æœæ²¡æœ‰å…¨å±€å®‰è£…ï¼‰
uv tool install mypy ruff
```

### ä»£ç è´¨é‡æ£€æŸ¥

```bash
# ä»£ç é£æ ¼æ£€æŸ¥
make lint

# ä»£ç æ ¼å¼åŒ–
make format-fix

# ç±»å‹æ£€æŸ¥
make type-check

# å®Œæ•´æ£€æŸ¥
make check

# è‡ªåŠ¨ä¿®å¤æ‰€æœ‰é—®é¢˜
make fix
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæµ‹è¯•
make test

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
uv run pytest --cov=app --cov-report=html
```

## ğŸ“‹ é¡¹ç›®ç»“æ„

```
openai-llm-proxy/
â”œâ”€â”€ app/                    # æ ¸å¿ƒåº”ç”¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py             # FastAPIåº”ç”¨ä¸»ä½“
â”‚   â”œâ”€â”€ config.py          # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ router.py          # æ¨¡å‹è·¯ç”±é€»è¾‘
â”‚   â”œâ”€â”€ models.py          # Pydanticæ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ middleware.py      # ä¸­é—´ä»¶ï¼ˆè¯·æ±‚IDã€æ—¥å¿—ç­‰ï¼‰
â”‚   â””â”€â”€ errors.py          # é”™è¯¯å¤„ç†
â”œâ”€â”€ config/                # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ config.yaml        # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ .axample          # é…ç½®ç¤ºä¾‹
â”œâ”€â”€ main.py               # åº”ç”¨å…¥å£
â”œâ”€â”€ pyproject.toml        # é¡¹ç›®ä¾èµ–é…ç½®
â”œâ”€â”€ mypy.ini             # MyPyç±»å‹æ£€æŸ¥é…ç½®
â”œâ”€â”€ Makefile             # å¼€å‘å·¥å…·å‘½ä»¤
â””â”€â”€ README.md            # é¡¹ç›®æ–‡æ¡£
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: å¯åŠ¨æ—¶æŠ¥é”™ "Invalid args for response field"**

A: è¿™æ˜¯FastAPIçš„è¿”å›ç±»å‹æ³¨è§£é—®é¢˜ï¼Œå·²é€šè¿‡æ·»åŠ  `response_model=None` è§£å†³ã€‚

**Q: æ¨¡å‹æœªæ‰¾åˆ°é”™è¯¯**

A: æ£€æŸ¥ `config/config.yaml` ä¸­æ˜¯å¦æ­£ç¡®é…ç½®äº†æ¨¡å‹æ˜ å°„ï¼š
```yaml
model_config:
  "your-model-name": provider_name
model_routes:
  provider_name:
    "your-model-name": "actual-model-id"
```

**Q: APIå¯†é’¥è®¤è¯å¤±è´¥**

A: ç¡®ä¿åœ¨ `config/config.yaml` çš„ `os_env` éƒ¨åˆ†è®¾ç½®äº†æ­£ç¡®çš„APIå¯†é’¥ã€‚

**Q: è¿æ¥è¶…æ—¶**

A: æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæä¾›å•†æœåŠ¡çŠ¶æ€ï¼Œå¯åœ¨é…ç½®ä¸­è°ƒæ•´è¶…æ—¶è®¾ç½®ã€‚

### æ—¥å¿—æŸ¥çœ‹

```bash
# å¯åŠ¨æ—¶æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python main.py --log-level debug

# æŸ¥çœ‹è¯·æ±‚IDè¿½è¸ª
grep "request_id" logs/app.log
```

## ğŸ¤ è´¡çŒ®

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»ºPull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [LiteLLM](https://github.com/BerriAI/litellm) - å¤šå‚å•†LLMç»Ÿä¸€æ¥å£
- [FastAPI](https://fastapi.tiangolo.com/) - ç°ä»£åŒ–çš„Python Webæ¡†æ¶
- [Pydantic](https://pydantic-docs.helpmanual.io/) - æ•°æ®éªŒè¯å’Œè®¾ç½®ç®¡ç†

## ğŸ“ æ”¯æŒ

å¦‚æœæ‚¨é‡åˆ°é—®é¢˜æˆ–æœ‰å»ºè®®ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„æ•…éšœæ’é™¤éƒ¨åˆ†
2. åœ¨GitHubä¸Šåˆ›å»ºIssue
3. æŸ¥çœ‹APIæ–‡æ¡£: http://localhost:8000/docs
